{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Data From Different Sources\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You're reading JSON data into a Pandas DataFrame.\n",
    "\n",
    "1.  **`import pandas as pd`**: Imports the Pandas library, giving you tools for working with DataFrames.\n",
    "2.  **`from io import StringIO`**: Imports `StringIO`, which lets you treat a string like a file.\n",
    "3.  **`Data = '{\"employee_name\": \"James\", \"email\": \"james@gmail.com\", \"job_profile\": [{\"title1\":\"Team Lead\", \"title2\":\"Sr. Developer\"}]}'`**: This is a JSON string containing information about an employee. Notice `job_profile` is a list containing a dictionary.\n",
    "4.  **`df=pd.read_json(StringIO(Data))`**:\n",
    "    * `StringIO(Data)`: Makes the JSON string behave like a readable file.\n",
    "    * `pd.read_json(...)`: Reads the JSON data from the \"file\" and creates a Pandas DataFrame named `df`.\n",
    "\n",
    "In short, this code takes a JSON string and turns it into a table-like structure (DataFrame) that you can easily work with using Pandas. The `job_profile` will likely be a column containing lists of dictionaries.\n",
    "\n",
    "\n",
    "`StringIO` is a class in Python's `io` module that allows you to treat a string as a file-like object.\n",
    "\n",
    "`StringIO` provides a convenient way to work with string data as if it were a file, especially when used with libraries like pandas that have functions designed to read from files or file-like objects. It avoids the need for temporary file creation and can make your code cleaner and more efficient when dealing with in-memory string data. Using `StringIO` ensures that you are providing the input in the format that `pd.read_json()` expects for reading from a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "Data = '{\"employee_name\": \"James\", \"email\": \"james@gmail.com\", \"job_profile\": [{\"title1\":\"Team Lead\", \"title2\":\"Sr. Developer\"}]}'\n",
    "print(type(Data))\n",
    "df=pd.read_json(StringIO(Data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_name</th>\n",
       "      <th>email</th>\n",
       "      <th>job_profile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>James</td>\n",
       "      <td>james@gmail.com</td>\n",
       "      <td>{'title1': 'Team Lead', 'title2': 'Sr. Develop...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  employee_name            email  \\\n",
       "0         James  james@gmail.com   \n",
       "\n",
       "                                         job_profile  \n",
       "0  {'title1': 'Team Lead', 'title2': 'Sr. Develop...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`df.to_json()` converts your entire Pandas DataFrame `df` into a JSON (JavaScript Object Notation) string. This format is commonly used for data transmission and storage because it's lightweight and readable by many programming languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"employee_name\":{\"0\":\"James\"},\"email\":{\"0\":\"james@gmail.com\"},\"job_profile\":{\"0\":{\"title1\":\"Team Lead\",\"title2\":\"Sr. Developer\"}}}'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function to_json in module pandas.core.generic:\n",
      "\n",
      "to_json(self, path_or_buf: 'FilePath | WriteBuffer[bytes] | WriteBuffer[str] | None' = None, *, orient: \"Literal['split', 'records', 'index', 'table', 'columns', 'values'] | None\" = None, date_format: 'str | None' = None, double_precision: 'int' = 10, force_ascii: 'bool_t' = True, date_unit: 'TimeUnit' = 'ms', default_handler: 'Callable[[Any], JSONSerializable] | None' = None, lines: 'bool_t' = False, compression: 'CompressionOptions' = 'infer', index: 'bool_t | None' = None, indent: 'int | None' = None, storage_options: 'StorageOptions | None' = None, mode: \"Literal['a', 'w']\" = 'w') -> 'str | None'\n",
      "    Convert the object to a JSON string.\n",
      "\n",
      "    Note NaN's and None will be converted to null and datetime objects\n",
      "    will be converted to UNIX timestamps.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    path_or_buf : str, path object, file-like object, or None, default None\n",
      "        String, path object (implementing os.PathLike[str]), or file-like\n",
      "        object implementing a write() function. If None, the result is\n",
      "        returned as a string.\n",
      "    orient : str\n",
      "        Indication of expected JSON string format.\n",
      "\n",
      "        * Series:\n",
      "\n",
      "            - default is 'index'\n",
      "            - allowed values are: {'split', 'records', 'index', 'table'}.\n",
      "\n",
      "        * DataFrame:\n",
      "\n",
      "            - default is 'columns'\n",
      "            - allowed values are: {'split', 'records', 'index', 'columns',\n",
      "              'values', 'table'}.\n",
      "\n",
      "        * The format of the JSON string:\n",
      "\n",
      "            - 'split' : dict like {'index' -> [index], 'columns' -> [columns],\n",
      "              'data' -> [values]}\n",
      "            - 'records' : list like [{column -> value}, ... , {column -> value}]\n",
      "            - 'index' : dict like {index -> {column -> value}}\n",
      "            - 'columns' : dict like {column -> {index -> value}}\n",
      "            - 'values' : just the values array\n",
      "            - 'table' : dict like {'schema': {schema}, 'data': {data}}\n",
      "\n",
      "            Describing the data, where data component is like ``orient='records'``.\n",
      "\n",
      "    date_format : {None, 'epoch', 'iso'}\n",
      "        Type of date conversion. 'epoch' = epoch milliseconds,\n",
      "        'iso' = ISO8601. The default depends on the `orient`. For\n",
      "        ``orient='table'``, the default is 'iso'. For all other orients,\n",
      "        the default is 'epoch'.\n",
      "    double_precision : int, default 10\n",
      "        The number of decimal places to use when encoding\n",
      "        floating point values. The possible maximal value is 15.\n",
      "        Passing double_precision greater than 15 will raise a ValueError.\n",
      "    force_ascii : bool, default True\n",
      "        Force encoded string to be ASCII.\n",
      "    date_unit : str, default 'ms' (milliseconds)\n",
      "        The time unit to encode to, governs timestamp and ISO8601\n",
      "        precision.  One of 's', 'ms', 'us', 'ns' for second, millisecond,\n",
      "        microsecond, and nanosecond respectively.\n",
      "    default_handler : callable, default None\n",
      "        Handler to call if object cannot otherwise be converted to a\n",
      "        suitable format for JSON. Should receive a single argument which is\n",
      "        the object to convert and return a serialisable object.\n",
      "    lines : bool, default False\n",
      "        If 'orient' is 'records' write out line-delimited json format. Will\n",
      "        throw ValueError if incorrect 'orient' since others are not\n",
      "        list-like.\n",
      "    compression : str or dict, default 'infer'\n",
      "        For on-the-fly compression of the output data. If 'infer' and 'path_or_buf' is\n",
      "        path-like, then detect compression from the following extensions: '.gz',\n",
      "        '.bz2', '.zip', '.xz', '.zst', '.tar', '.tar.gz', '.tar.xz' or '.tar.bz2'\n",
      "        (otherwise no compression).\n",
      "        Set to ``None`` for no compression.\n",
      "        Can also be a dict with key ``'method'`` set\n",
      "        to one of {``'zip'``, ``'gzip'``, ``'bz2'``, ``'zstd'``, ``'xz'``, ``'tar'``} and\n",
      "        other key-value pairs are forwarded to\n",
      "        ``zipfile.ZipFile``, ``gzip.GzipFile``,\n",
      "        ``bz2.BZ2File``, ``zstandard.ZstdCompressor``, ``lzma.LZMAFile`` or\n",
      "        ``tarfile.TarFile``, respectively.\n",
      "        As an example, the following could be passed for faster compression and to create\n",
      "        a reproducible gzip archive:\n",
      "        ``compression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1}``.\n",
      "\n",
      "        .. versionadded:: 1.5.0\n",
      "            Added support for `.tar` files.\n",
      "\n",
      "        .. versionchanged:: 1.4.0 Zstandard support.\n",
      "\n",
      "    index : bool or None, default None\n",
      "        The index is only used when 'orient' is 'split', 'index', 'column',\n",
      "        or 'table'. Of these, 'index' and 'column' do not support\n",
      "        `index=False`.\n",
      "\n",
      "    indent : int, optional\n",
      "       Length of whitespace used to indent each record.\n",
      "\n",
      "    storage_options : dict, optional\n",
      "        Extra options that make sense for a particular storage connection, e.g.\n",
      "        host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      "        are forwarded to ``urllib.request.Request`` as header options. For other\n",
      "        URLs (e.g. starting with \"s3://\", and \"gcs://\") the key-value pairs are\n",
      "        forwarded to ``fsspec.open``. Please see ``fsspec`` and ``urllib`` for more\n",
      "        details, and for more examples on storage options refer `here\n",
      "        <https://pandas.pydata.org/docs/user_guide/io.html?\n",
      "        highlight=storage_options#reading-writing-remote-files>`_.\n",
      "\n",
      "    mode : str, default 'w' (writing)\n",
      "        Specify the IO mode for output when supplying a path_or_buf.\n",
      "        Accepted args are 'w' (writing) and 'a' (append) only.\n",
      "        mode='a' is only supported when lines is True and orient is 'records'.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    None or str\n",
      "        If path_or_buf is None, returns the resulting json format as a\n",
      "        string. Otherwise returns None.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    read_json : Convert a JSON string to pandas object.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    The behavior of ``indent=0`` varies from the stdlib, which does not\n",
      "    indent the output but does insert newlines. Currently, ``indent=0``\n",
      "    and the default ``indent=None`` are equivalent in pandas, though this\n",
      "    may change in a future release.\n",
      "\n",
      "    ``orient='table'`` contains a 'pandas_version' field under 'schema'.\n",
      "    This stores the version of `pandas` used in the latest revision of the\n",
      "    schema.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> from json import loads, dumps\n",
      "    >>> df = pd.DataFrame(\n",
      "    ...     [[\"a\", \"b\"], [\"c\", \"d\"]],\n",
      "    ...     index=[\"row 1\", \"row 2\"],\n",
      "    ...     columns=[\"col 1\", \"col 2\"],\n",
      "    ... )\n",
      "\n",
      "    >>> result = df.to_json(orient=\"split\")\n",
      "    >>> parsed = loads(result)\n",
      "    >>> dumps(parsed, indent=4)  # doctest: +SKIP\n",
      "    {\n",
      "        \"columns\": [\n",
      "            \"col 1\",\n",
      "            \"col 2\"\n",
      "        ],\n",
      "        \"index\": [\n",
      "            \"row 1\",\n",
      "            \"row 2\"\n",
      "        ],\n",
      "        \"data\": [\n",
      "            [\n",
      "                \"a\",\n",
      "                \"b\"\n",
      "            ],\n",
      "            [\n",
      "                \"c\",\n",
      "                \"d\"\n",
      "            ]\n",
      "        ]\n",
      "    }\n",
      "\n",
      "    Encoding/decoding a Dataframe using ``'records'`` formatted JSON.\n",
      "    Note that index labels are not preserved with this encoding.\n",
      "\n",
      "    >>> result = df.to_json(orient=\"records\")\n",
      "    >>> parsed = loads(result)\n",
      "    >>> dumps(parsed, indent=4)  # doctest: +SKIP\n",
      "    [\n",
      "        {\n",
      "            \"col 1\": \"a\",\n",
      "            \"col 2\": \"b\"\n",
      "        },\n",
      "        {\n",
      "            \"col 1\": \"c\",\n",
      "            \"col 2\": \"d\"\n",
      "        }\n",
      "    ]\n",
      "\n",
      "    Encoding/decoding a Dataframe using ``'index'`` formatted JSON:\n",
      "\n",
      "    >>> result = df.to_json(orient=\"index\")\n",
      "    >>> parsed = loads(result)\n",
      "    >>> dumps(parsed, indent=4)  # doctest: +SKIP\n",
      "    {\n",
      "        \"row 1\": {\n",
      "            \"col 1\": \"a\",\n",
      "            \"col 2\": \"b\"\n",
      "        },\n",
      "        \"row 2\": {\n",
      "            \"col 1\": \"c\",\n",
      "            \"col 2\": \"d\"\n",
      "        }\n",
      "    }\n",
      "\n",
      "    Encoding/decoding a Dataframe using ``'columns'`` formatted JSON:\n",
      "\n",
      "    >>> result = df.to_json(orient=\"columns\")\n",
      "    >>> parsed = loads(result)\n",
      "    >>> dumps(parsed, indent=4)  # doctest: +SKIP\n",
      "    {\n",
      "        \"col 1\": {\n",
      "            \"row 1\": \"a\",\n",
      "            \"row 2\": \"c\"\n",
      "        },\n",
      "        \"col 2\": {\n",
      "            \"row 1\": \"b\",\n",
      "            \"row 2\": \"d\"\n",
      "        }\n",
      "    }\n",
      "\n",
      "    Encoding/decoding a Dataframe using ``'values'`` formatted JSON:\n",
      "\n",
      "    >>> result = df.to_json(orient=\"values\")\n",
      "    >>> parsed = loads(result)\n",
      "    >>> dumps(parsed, indent=4)  # doctest: +SKIP\n",
      "    [\n",
      "        [\n",
      "            \"a\",\n",
      "            \"b\"\n",
      "        ],\n",
      "        [\n",
      "            \"c\",\n",
      "            \"d\"\n",
      "        ]\n",
      "    ]\n",
      "\n",
      "    Encoding with Table Schema:\n",
      "\n",
      "    >>> result = df.to_json(orient=\"table\")\n",
      "    >>> parsed = loads(result)\n",
      "    >>> dumps(parsed, indent=4)  # doctest: +SKIP\n",
      "    {\n",
      "        \"schema\": {\n",
      "            \"fields\": [\n",
      "                {\n",
      "                    \"name\": \"index\",\n",
      "                    \"type\": \"string\"\n",
      "                },\n",
      "                {\n",
      "                    \"name\": \"col 1\",\n",
      "                    \"type\": \"string\"\n",
      "                },\n",
      "                {\n",
      "                    \"name\": \"col 2\",\n",
      "                    \"type\": \"string\"\n",
      "                }\n",
      "            ],\n",
      "            \"primaryKey\": [\n",
      "                \"index\"\n",
      "            ],\n",
      "            \"pandas_version\": \"1.4.0\"\n",
      "        },\n",
      "        \"data\": [\n",
      "            {\n",
      "                \"index\": \"row 1\",\n",
      "                \"col 1\": \"a\",\n",
      "                \"col 2\": \"b\"\n",
      "            },\n",
      "            {\n",
      "                \"index\": \"row 2\",\n",
      "                \"col 1\": \"c\",\n",
      "                \"col 2\": \"d\"\n",
      "            }\n",
      "        ]\n",
      "    }\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# display the docstring for the to_json() function, which clearly lists and describes \n",
    "# all the possible values for the orient parameter.\n",
    "help(pd.DataFrame.to_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`df.to_json(orient='index')` converts your DataFrame `df` into a JSON string. The `orient='index'` part means each **row** of your DataFrame becomes a separate JSON object. The keys of these objects are the **index labels** of the rows, and the values are dictionaries containing the column names and their corresponding row values.\n",
    "\n",
    "**Example:**\n",
    "\n",
    "If your DataFrame `df` looks like this:\n",
    "\n",
    "```\n",
    "   col1  col2\n",
    "a     1     3\n",
    "b     2     4\n",
    "```\n",
    "\n",
    "Then `df.to_json(orient='index')` would produce a JSON string like this:\n",
    "\n",
    "```json\n",
    "{\"a\":{\"col1\":1,\"col2\":3},\"b\":{\"col1\":2,\"col2\":4}}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"0\":{\"employee_name\":\"James\",\"email\":\"james@gmail.com\",\"job_profile\":{\"title1\":\"Team Lead\",\"title2\":\"Sr. Developer\"}}}'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_json(orient='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`df.to_json(orient='records')` converts your DataFrame `df` into a JSON string where each row becomes a separate JSON object (a dictionary). The `records` orientation arranges the data as a list of these row-objects.\n",
    "\n",
    "**Short, simple code example:**\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "data = {'col1': [1, 2], 'col2': ['a', 'b']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "json_output = df.to_json(orient='records')\n",
    "print(json_output)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "\n",
    "```json\n",
    "[{\"col1\":1,\"col2\":\"a\"},{\"col1\":2,\"col2\":\"b\"}]\n",
    "```\n",
    "\n",
    "Each dictionary in the list represents a row from your DataFrame, with keys as column names and values as the row data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"employee_name\":\"James\",\"email\":\"james@gmail.com\",\"job_profile\":{\"title1\":\"Team Lead\",\"title2\":\"Sr. Developer\"}}]'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_json(orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data from Internet URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\",header=None)\n",
    "# df=pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1     2     3     4    5     6     7     8     9     10    11    12  \\\n",
       "0   1  14.23  1.71  2.43  15.6  127  2.80  3.06  0.28  2.29  5.64  1.04  3.92   \n",
       "1   1  13.20  1.78  2.14  11.2  100  2.65  2.76  0.26  1.28  4.38  1.05  3.40   \n",
       "2   1  13.16  2.36  2.67  18.6  101  2.80  3.24  0.30  2.81  5.68  1.03  3.17   \n",
       "3   1  14.37  1.95  2.50  16.8  113  3.85  3.49  0.24  2.18  7.80  0.86  3.45   \n",
       "4   1  13.24  2.59  2.87  21.0  118  2.80  2.69  0.39  1.82  4.32  1.04  2.93   \n",
       "\n",
       "     13  \n",
       "0  1065  \n",
       "1  1050  \n",
       "2  1185  \n",
       "3  1480  \n",
       "4   735  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write object to a comma-separated values (csv) file.\n",
    "df.to_csv(\"wine.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lxml in c:\\users\\kkapil\\appdata\\local\\anaconda3\\lib\\site-packages (5.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting html5lib\n",
      "  Downloading html5lib-1.1-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: six>=1.9 in c:\\users\\kkapil\\appdata\\local\\anaconda3\\lib\\site-packages (from html5lib) (1.16.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\kkapil\\appdata\\local\\anaconda3\\lib\\site-packages (from html5lib) (0.5.1)\n",
      "Downloading html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
      "Installing collected packages: html5lib\n",
      "Successfully installed html5lib-1.1\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\kkapil\\appdata\\local\\anaconda3\\lib\\site-packages (4.12.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\kkapil\\appdata\\local\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install html5lib\n",
    "!pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.fdic.gov/resources/resolutions/bank-failures/failed-bank-list/\"\n",
    "\n",
    "df=pd.read_html(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bank Name</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Cert</th>\n",
       "      <th>Acquiring Institution</th>\n",
       "      <th>Closing Date</th>\n",
       "      <th>Fund  Sort ascending</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pulaski Savings Bank</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>28611</td>\n",
       "      <td>Millennium Bank</td>\n",
       "      <td>January 17, 2025</td>\n",
       "      <td>10548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The First National Bank of Lindsay</td>\n",
       "      <td>Lindsay</td>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>4134</td>\n",
       "      <td>First Bank &amp; Trust Co., Duncan, OK</td>\n",
       "      <td>October 18, 2024</td>\n",
       "      <td>10547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Republic First Bank dba Republic Bank</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>27332</td>\n",
       "      <td>Fulton Bank, National Association</td>\n",
       "      <td>April 26, 2024</td>\n",
       "      <td>10546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Citizens Bank</td>\n",
       "      <td>Sac City</td>\n",
       "      <td>Iowa</td>\n",
       "      <td>8758</td>\n",
       "      <td>Iowa Trust &amp; Savings Bank</td>\n",
       "      <td>November 3, 2023</td>\n",
       "      <td>10545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Heartland Tri-State Bank</td>\n",
       "      <td>Elkhart</td>\n",
       "      <td>Kansas</td>\n",
       "      <td>25851</td>\n",
       "      <td>Dream First Bank, N.A.</td>\n",
       "      <td>July 28, 2023</td>\n",
       "      <td>10544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>First Republic Bank</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>California</td>\n",
       "      <td>59017</td>\n",
       "      <td>JPMorgan Chase Bank, N.A.</td>\n",
       "      <td>May 1, 2023</td>\n",
       "      <td>10543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Signature Bank</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>57053</td>\n",
       "      <td>Flagstar Bank, N.A.</td>\n",
       "      <td>March 12, 2023</td>\n",
       "      <td>10540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Silicon Valley Bank</td>\n",
       "      <td>Santa Clara</td>\n",
       "      <td>California</td>\n",
       "      <td>24735</td>\n",
       "      <td>First Citizens Bank &amp; Trust Company</td>\n",
       "      <td>March 10, 2023</td>\n",
       "      <td>10539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Almena State Bank</td>\n",
       "      <td>Almena</td>\n",
       "      <td>Kansas</td>\n",
       "      <td>15426</td>\n",
       "      <td>Equity Bank</td>\n",
       "      <td>October 23, 2020</td>\n",
       "      <td>10538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>First City Bank of Florida</td>\n",
       "      <td>Fort Walton Beach</td>\n",
       "      <td>Florida</td>\n",
       "      <td>16748</td>\n",
       "      <td>United Fidelity Bank, fsb</td>\n",
       "      <td>October 16, 2020</td>\n",
       "      <td>10537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Bank Name               City         State  \\\n",
       "0                   Pulaski Savings Bank            Chicago      Illinois   \n",
       "1     The First National Bank of Lindsay            Lindsay      Oklahoma   \n",
       "2  Republic First Bank dba Republic Bank       Philadelphia  Pennsylvania   \n",
       "3                          Citizens Bank           Sac City          Iowa   \n",
       "4               Heartland Tri-State Bank            Elkhart        Kansas   \n",
       "5                    First Republic Bank      San Francisco    California   \n",
       "6                         Signature Bank           New York      New York   \n",
       "7                    Silicon Valley Bank        Santa Clara    California   \n",
       "8                      Almena State Bank             Almena        Kansas   \n",
       "9             First City Bank of Florida  Fort Walton Beach       Florida   \n",
       "\n",
       "    Cert                Acquiring Institution      Closing Date  \\\n",
       "0  28611                      Millennium Bank  January 17, 2025   \n",
       "1   4134   First Bank & Trust Co., Duncan, OK  October 18, 2024   \n",
       "2  27332    Fulton Bank, National Association    April 26, 2024   \n",
       "3   8758            Iowa Trust & Savings Bank  November 3, 2023   \n",
       "4  25851               Dream First Bank, N.A.     July 28, 2023   \n",
       "5  59017            JPMorgan Chase Bank, N.A.       May 1, 2023   \n",
       "6  57053                  Flagstar Bank, N.A.    March 12, 2023   \n",
       "7  24735  First Citizens Bank & Trust Company    March 10, 2023   \n",
       "8  15426                          Equity Bank  October 23, 2020   \n",
       "9  16748            United Fidelity Bank, fsb  October 16, 2020   \n",
       "\n",
       "   Fund  Sort ascending  \n",
       "0                 10548  \n",
       "1                 10547  \n",
       "2                 10546  \n",
       "3                 10545  \n",
       "4                 10544  \n",
       "5                 10543  \n",
       "6                 10540  \n",
       "7                 10539  \n",
       "8                 10538  \n",
       "9                 10537  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MCC</th>\n",
       "      <th>MNC</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Operator</th>\n",
       "      <th>Status</th>\n",
       "      <th>Bands (MHz)</th>\n",
       "      <th>References and notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>901</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Webbing</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>MVNO</td>\n",
       "      <td>Former ICO Satellite Management[51][52]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>901</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GlobalmatiX AG</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Former Sense Communications International; veh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>901</td>\n",
       "      <td>3</td>\n",
       "      <td>Iridium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Operational</td>\n",
       "      <td>Satellite</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>901</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BBIX Singapore Pte. Ltd.</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Former Globalstar[54]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>901</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Thuraya RMSS Network</td>\n",
       "      <td>Operational</td>\n",
       "      <td>Satellite</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>902</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MulteFire Alliance</td>\n",
       "      <td>Operational</td>\n",
       "      <td>LTE</td>\n",
       "      <td>[6][126]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>991</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>World's Global Telecom</td>\n",
       "      <td>Not operational</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>temporarily assigned until 15 January 2021[104...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>991</td>\n",
       "      <td>2</td>\n",
       "      <td>5G Croco</td>\n",
       "      <td>Orange S.A.</td>\n",
       "      <td>Not operational</td>\n",
       "      <td>5G</td>\n",
       "      <td>temporarily assigned until 6 August 2022[128][...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>991</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Halys SAS</td>\n",
       "      <td>Not operational</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>temporary assignment for trial until 5 April 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>991</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E-Space Inc.</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Satellite</td>\n",
       "      <td>temporary assignment for trial until 17 Oct 20...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     MCC  MNC     Brand                  Operator           Status  \\\n",
       "0    901    1       NaN                   Webbing          Unknown   \n",
       "1    901    2       NaN            GlobalmatiX AG          Unknown   \n",
       "2    901    3   Iridium                       NaN      Operational   \n",
       "3    901    4       NaN  BBIX Singapore Pte. Ltd.          Unknown   \n",
       "4    901    5       NaN      Thuraya RMSS Network      Operational   \n",
       "..   ...  ...       ...                       ...              ...   \n",
       "99   902    1       NaN        MulteFire Alliance      Operational   \n",
       "100  991    1       NaN    World's Global Telecom  Not operational   \n",
       "101  991    2  5G Croco               Orange S.A.  Not operational   \n",
       "102  991    3       NaN                 Halys SAS  Not operational   \n",
       "103  991    4       NaN              E-Space Inc.          Unknown   \n",
       "\n",
       "    Bands (MHz)                               References and notes  \n",
       "0          MVNO            Former ICO Satellite Management[51][52]  \n",
       "1       Unknown  Former Sense Communications International; veh...  \n",
       "2     Satellite                                                NaN  \n",
       "3       Unknown                              Former Globalstar[54]  \n",
       "4     Satellite                                                NaN  \n",
       "..          ...                                                ...  \n",
       "99          LTE                                           [6][126]  \n",
       "100     Unknown  temporarily assigned until 15 January 2021[104...  \n",
       "101          5G  temporarily assigned until 6 August 2022[128][...  \n",
       "102     Unknown  temporary assignment for trial until 5 April 2...  \n",
       "103   Satellite  temporary assignment for trial until 17 Oct 20...  \n",
       "\n",
       "[104 rows x 7 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url=\"https://en.wikipedia.org/wiki/Mobile_country_code\"\n",
    "# pd.read_html(url,match=\"Country\",header=0)[0]\n",
    "\n",
    "pd.read_html(url,match=\"91\",header=0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in c:\\users\\kkapil\\appdata\\local\\anaconda3\\lib\\site-packages (3.1.5)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\kkapil\\appdata\\local\\anaconda3\\lib\\site-packages (from openpyxl) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Karan</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jack</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>John</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Name  Age\n",
       "0  Karan   32\n",
       "1   Jack   34\n",
       "2   John   31"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_excel=pd.read_excel('data.xlsx')\n",
    "df_excel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`df_excel.to_pickle('df_excel')` saves the pandas DataFrame named `df_excel` to a file named 'df_excel' in the pickle format.\n",
    "\n",
    "**In essence:**\n",
    "\n",
    "It performs **serialization** of the DataFrame into a binary file, preserving its structure and data types. You can later load it back into a DataFrame using `pd.read_pickle('df_excel')`.\n",
    "\n",
    "**Use it when:**\n",
    "\n",
    "* You want to save a DataFrame for **faster reading** in a future Python session compared to text-based formats like CSV.\n",
    "* You need to **preserve the data types** and structure of the DataFrame exactly as they are.\n",
    "\n",
    "The resulting file 'df_excel' will be in a binary format, not easily human-readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_excel.to_pickle('df_excel') # file saved but not direcly readable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Karan</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jack</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>John</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Name  Age\n",
       "0  Karan   32\n",
       "1   Jack   34\n",
       "2   John   31"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read pickle file\n",
    "pd.read_pickle('df_excel')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
